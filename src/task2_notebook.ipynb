{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"/home/hack12/ensemble-ai2024/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hack12/ensemble-ai2024/venv/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from pathlib import Path\n",
    "from taskdataset import TaskDataset\n",
    "import hydra\n",
    "import numpy as np\n",
    "import torch\n",
    "import wandb\n",
    "from omegaconf import omegaconf, OmegaConf\n",
    "from torch import optim, nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import RandomAffine\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from src.config import Config\n",
    "# from src.data.custom_dataset import EncodingsToLabels, EncodingsDataset\n",
    "from src.models.linear_head import Net, MapperNet\n",
    "from src.transforms.affine import AffineTransform, AffineAndPadAndShuffleTransform, PadAndShuffleTransform\n",
    "from src.transforms.binary import BinaryTransform\n",
    "import json\n",
    "from typing import List\n",
    "import requests\n",
    "import argparse\n",
    "from torch.utils.data import Dataset\n",
    "# import end2end_stealing.vision_transformer as vits\n",
    "import torchvision.models as models\n",
    "import torchvision\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data.to(device))\n",
    "        loss = criterion(output, target.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "        epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "               100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wodzes(features, ids, n=10, near_dist=None):\n",
    "    ids_to_return = []\n",
    "    # features_to_return = []\n",
    "    indexes = []\n",
    "\n",
    "    random_index = random.randint(0, len(features))\n",
    "\n",
    "    # features_to_return.append(features[random_index])\n",
    "    ids_to_return.append(ids[random_index])\n",
    "    indexes.append(random_index)\n",
    "\n",
    "    # near_indices = []\n",
    "    near_images = []\n",
    "\n",
    "    for i in tqdm(range(n)):\n",
    "        distances = torch.cdist(features[indexes], features)\n",
    "        sum_distances = torch.sum(distances, dim=0, keepdim=True)\n",
    "        sorted_indices = torch.argsort(sum_distances, descending=True)[0]\n",
    "        # max_value_index = torch.argmax(sum_distances).item()\n",
    "        # if near_dist is not None:\n",
    "        #     max_val_distances = torch.cdist(features[max_value_index], features)\n",
    "        #     mask = max_val_distances < near_dist\n",
    "        #     indices = torch.nonzero(mask, as_tuple=False)\n",
    "        #     near_indices.extend(indices)\n",
    "        #     near_images.extend([dataset[i] for i in indices])\n",
    "        for idx in sorted_indices:\n",
    "            if idx not in indexes:\n",
    "                max_value_index = idx.item()\n",
    "                break\n",
    "\n",
    "        indexes.append(max_value_index)\n",
    "        ids_to_return.append(ids[max_value_index])\n",
    "\n",
    "    # indexes.extend(near_indices)\n",
    "    ids_to_return.extend(near_images)\n",
    "\n",
    "    return ids_to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sybil_attack(ids: List[int], home_or_defense: str, binary_or_affine: str):\n",
    "    if home_or_defense not in [\"home\", \"defense\"] or binary_or_affine not in [\"binary\", \"affine\"]:\n",
    "        raise \"Invalid endpoint\"\n",
    "    \n",
    "    TEAM_TOKEN = \"8J40ASDQOjfeeSKL\"\n",
    "    SERVER_URL = \"http://34.71.138.79:9090\"\n",
    "\n",
    "    ENDPOINT = f\"/sybil/{binary_or_affine}/{home_or_defense}\"\n",
    "    URL = SERVER_URL + ENDPOINT\n",
    "\n",
    "    ids = ids = \",\".join(map(str, ids))\n",
    "\n",
    "    response = requests.get(\n",
    "        URL, params={\"ids\": ids}, headers={\"token\": TEAM_TOKEN}\n",
    "    )\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return json.loads(response.content)[\"representations\"]\n",
    "    else:\n",
    "        raise Exception(f\"Request failed. Status code: {response.status_code}, content: {response.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sybil_reset(binary_or_affine: str, home_or_defense: str):\n",
    "    TEAM_TOKEN = \"8J40ASDQOjfeeSKL\"\n",
    "    SERVER_URL = \"http://34.71.138.79:9090\"\n",
    "    \n",
    "    if binary_or_affine not in [\"binary\", \"affine\"]:\n",
    "        raise Exception(\"Invalid endpoint\")\n",
    "    \n",
    "    if home_or_defense not in [\"home\", \"defense\"]:\n",
    "        raise Exception(\"Invalid endpoint\")\n",
    "\n",
    "    endpoint = f\"/sybil/{binary_or_affine}/reset/{home_or_defense}\"\n",
    "    url = SERVER_URL + endpoint\n",
    "    response = requests.post(url, headers={\"token\": TEAM_TOKEN})\n",
    "    if response.status_code == 200:\n",
    "        print(\"Request ok\")\n",
    "        print(response.json())\n",
    "    else:\n",
    "        raise Exception(\n",
    "            f\"Sybil reset failed. Code: {response.status_code}, content: {response.json()}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request ok\n",
      "{'msg': 'Successful sybil affine reset defense'}\n"
     ]
    }
   ],
   "source": [
    "sybil_reset('affine', 'defense')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncodingsDataset(Dataset):\n",
    "    def __init__(self, transformed_encodings, encodings):\n",
    "        self.transformed_encodings = torch.from_numpy(transformed_encodings.astype('float32'))\n",
    "        self.encodings = torch.from_numpy(encodings.astype('float32'))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.transformed_encodings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.transformed_encodings[idx], self.encodings[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.manual_seed(SEED)\n",
    "# torch.use_deterministic_algorithms(True)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "device = torch.device(f\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Identity()\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "victim_model = models.__dict__[\"resnet50\"]()\n",
    "checkpoint = torch.load(\n",
    "    \"/home/hack12/ensemble-ai2024/end2end-stealing/pretrained_weights/checkpoint_0099.pth.tar\",\n",
    "    map_location=\"cpu\",\n",
    ")\n",
    "state_dict = checkpoint[\"state_dict\"]\n",
    "for k in list(state_dict.keys()):\n",
    "    # retain only encoder up to before the embedding layer\n",
    "    if k.startswith(\"module.encoder\") and not k.startswith(\"module.encoder.fc\"):\n",
    "        # remove prefix\n",
    "        state_dict[k[len(\"module.encoder.\") :]] = state_dict[k]\n",
    "    # delete renamed or unused k\n",
    "    del state_dict[k]\n",
    "# print(\"state dict\", state_dict.keys())\n",
    "victim_model.load_state_dict(state_dict, strict=False)\n",
    "victim_model.fc = torch.nn.Identity()\n",
    "victim_model.cuda()\n",
    "victim_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torch.load('/home/hack12/ensemble-ai2024/src/data/SybilAttack.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "to_tensor = torchvision.transforms.ToTensor()\n",
    "\n",
    "for iid, img, label in dataset:\n",
    "    with torch.no_grad():\n",
    "        img = img.convert(\"RGB\")\n",
    "        img = to_tensor(img).unsqueeze(0)\n",
    "\n",
    "        victim_model(img.to(\"cuda\"))\n",
    "        features.append(victim_model(img.to(\"cuda\")).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = torch.from_numpy(np.array(features))\n",
    "features = features.view(features.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSFORMATION = 'affine'\n",
    "OVERLAP = 1000\n",
    "learning_rate = 3e-5\n",
    "batch_size = 64\n",
    "mapper_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformation = TRANSFORMATION\n",
    "overlap = OVERLAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "EVAL_B_SIZE = 2000 - overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ids = dataset.ids\n",
    "\n",
    "# np.save('ids_A', ids_A)\n",
    "ids_A = np.load('ids_A.npy')\n",
    "# ids_A = np.array(random.sample(dataset_ids, 2000))\n",
    "# ids_A = get_wodzes(features, dataset_ids, n=2000)\n",
    "unused_ids = [id for id in dataset_ids if id not in ids_A]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlapping_examples_index = random.sample(range(0, 2000), overlap)\n",
    "overlapping_examples = ids_A[overlapping_examples_index]\n",
    "\n",
    "n_items = overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pobieram te dane z A, 2 tysiÄ…ce\n",
    "\n",
    "\n",
    "# real_data_A = sybil_attack(ids_A.tolist(), 'home', transformation)\n",
    "# real_data_A = np.array(real_data_A)\n",
    "\n",
    "# np.save('real_A_data', real_data_A)\n",
    "real_data_A = np.load('real_A_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# te dane z 2000 wybrane do treningu \n",
    "train_embeds_A = real_data_A[overlapping_examples_index]\n",
    "\n",
    "results['ids'] = ids_A\n",
    "results['features'] = real_data_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2000)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results['ids']), len(results['features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_OUTPUT = real_data_A[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_embeds_B = sybil_attack(overlapping_examples, 'defense', transformation)\n",
    "# train_embeds_B = np.array(train_embeds_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# if len(unused_ids) >= EVAL_B_SIZE:\n",
    "#     eval_B_index = random.sample(range(0, len(unused_ids)), EVAL_B_SIZE)\n",
    "#     eval_B_ids = np.array(unused_ids)[eval_B_index]\n",
    "#     unused_ids = [id for id in unused_ids if id not in eval_B_ids]\n",
    "# else:\n",
    "#     eval_B_ids = unused_ids\n",
    "#     unused_ids = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_embeds_B = sybil_attack(eval_B_ids, 'defense', transformation)\n",
    "# eval_embeds_B = torch.from_numpy(np.array(eval_embeds_B).astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = EncodingsDataset(train_embeds_B, train_embeds_A)\n",
    "\n",
    "# train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapper = MapperNet(train_embeds_B[0].shape[0],\n",
    "#                     train_embeds_A[0].shape[0],\n",
    "#                     n_hidden=MODEL_OUTPUT).to(device)\n",
    "# criterion = nn.MSELoss()\n",
    "# optimizer = torch.optim.Adam(mapper.parameters(), lr=learning_rate)\n",
    "\n",
    "# print(\"Training mapper...\")\n",
    "# for epoch in range(1, mapper_epochs):\n",
    "#     train(epoch, mapper, train_loader, criterion, optimizer, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request ok\n",
      "{'msg': 'Successful sybil affine reset defense'}\n"
     ]
    }
   ],
   "source": [
    "while unused_ids:\n",
    "\n",
    "    sybil_reset('affine', 'defense')\n",
    "\n",
    "    time.sleep(20)\n",
    "\n",
    "    # print('overlapping len', len(overlapping_examples))\n",
    "\n",
    "    # train_embeds_B = sybil_attack(overlapping_examples, 'defense', transformation)\n",
    "    # train_embeds_B = np.array(train_embeds_B)\n",
    "\n",
    "\n",
    "    if len(unused_ids) >= EVAL_B_SIZE:\n",
    "        eval_B_index = random.sample(range(0, len(unused_ids)), EVAL_B_SIZE)\n",
    "        eval_B_ids = np.array(unused_ids)[eval_B_index]\n",
    "        unused_ids = [id for id in unused_ids if id not in eval_B_ids]\n",
    "    else:\n",
    "        eval_B_ids = unused_ids\n",
    "        unused_ids = []\n",
    "\n",
    "    print('unused_ids', len(unused_ids))\n",
    "    \n",
    "    ask_for_B = np.concatenate((overlapping_examples, eval_B_ids))\n",
    "\n",
    "    # eval_embeds_B = sybil_attack(eval_B_ids, 'defense', transformation)\n",
    "    # eval_embeds_B = torch.from_numpy(np.array(eval_embeds_B).astype('float32'))\n",
    "\n",
    "    print('ask len', len(ask_for_B))\n",
    "    \n",
    "    for i in range(20):\n",
    "        try:\n",
    "            asked_embeds_B = sybil_attack(ask_for_B, 'defense', transformation)\n",
    "            break\n",
    "        except:\n",
    "            sybil_reset('affine', 'defense')\n",
    "            time.sleep(2)\n",
    "            continue\n",
    "    \n",
    "    train_embeds_B = asked_embeds_B[:len(overlapping_examples)]\n",
    "    train_embeds_B = np.array(train_embeds_B)\n",
    "    eval_embeds_B = asked_embeds_B[len(overlapping_examples):]\n",
    "    eval_embeds_B = torch.from_numpy(np.array(eval_embeds_B).astype('float32'))\n",
    "\n",
    "    train_dataset = EncodingsDataset(train_embeds_B, train_embeds_A)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    mapper = MapperNet(train_embeds_B[0].shape[0],\n",
    "                        train_embeds_A[0].shape[0],\n",
    "                        n_hidden=MODEL_OUTPUT).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(mapper.parameters(), lr=learning_rate)\n",
    "\n",
    "    print(\"Training mapper...\")\n",
    "    for epoch in range(1, mapper_epochs):\n",
    "        train(epoch, mapper, train_loader, criterion, optimizer, device=device)\n",
    "\n",
    "    reconstructed_encodings_test = []\n",
    "    for encoding in tqdm(eval_embeds_B):\n",
    "        reconstructed_encoding = mapper(encoding.to(device))\n",
    "        reconstructed_encodings_test.append(reconstructed_encoding.detach().to(\"cpu\"))\n",
    "    reconstructed_encodings_test = torch.cat(reconstructed_encodings_test).reshape(\n",
    "        len(eval_embeds_B), -1)\n",
    "\n",
    "    results['ids'] = np.concatenate((results['ids'], eval_B_ids))\n",
    "    results['features'] = np.concatenate((results['features'], reconstructed_encodings_test.numpy()))\n",
    "\n",
    "    print('results len', len(results['ids']))\n",
    "\n",
    "    # sybil_reset('affine', 'defense')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18500"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results['ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\n",
    "        \"example_submission.npz\",\n",
    "        ids=results['ids'],\n",
    "        representations=results['features'],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a mapper\n",
    "while unused_ids:\n",
    "    \n",
    "    train_embeds_B = sybil_attack(overlapping_examples, 'defense', transformation)\n",
    "    \n",
    "    if len(unused_ids) >= EVAL_B_SIZE:\n",
    "        eval_B_ids = random.sample(range(0, len(unused_ids)), EVAL_B_SIZE)\n",
    "        unused_ids = [id for id in unused_ids if id not in eval_B_ids]\n",
    "    else:\n",
    "        eval_B_ids = unused_ids\n",
    "        unused_ids = []\n",
    "\n",
    "    eval_embeds_B = sybil_attack(eval_B_ids, 'defense', transformation)\n",
    "\n",
    "    train_dataset = EncodingsDataset(train_embeds_B, train_embeds_A)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    mapper = MapperNet(train_embeds_B[0][0].shape[0],\n",
    "                        train_embeds_A[0][0].shape[0],\n",
    "                        n_hidden=MODEL_OUTPUT).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(mapper.parameters(), lr=learning_rate)\n",
    "\n",
    "    print(\"Training mapper...\")\n",
    "    for epoch in range(1, mapper_epochs):\n",
    "        train(epoch, mapper, train_loader, criterion, optimizer, device=device)\n",
    "\n",
    "    reconstructed_encodings_test = []\n",
    "    for encoding in tqdm(eval_embeds_B):\n",
    "        reconstructed_encoding = mapper(encoding.to(device))\n",
    "        reconstructed_encodings_test.append(reconstructed_encoding.detach().to(\"cpu\"))\n",
    "    reconstructed_encodings_test = torch.cat(reconstructed_encodings_test).reshape(\n",
    "        len(eval_embeds_B), -1)\n",
    "\n",
    "    results['ids'] = np.concatenate(results['ids'], eval_B_ids)\n",
    "    results['features'] = np.concatenate(results['features'], reconstructed_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_results(TRANSFORMATION, OVERLAP)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
